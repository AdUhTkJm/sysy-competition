#!/bin/python3
import argparse;
import subprocess as proc;
import os;
import hashlib;
import pickle;
import tempfile;
from pathlib import Path;

# This is used to build and test the compiler only.
# Large part of the scripts are generated by ChatGPT and Deepseek.

parser = argparse.ArgumentParser()
parser.add_argument("-g", "--gdb", action="store_true")
parser.add_argument("-V", "--valgrind", action="store_true")
parser.add_argument("-v", "--verbose", action="store_true")
parser.add_argument("-s", "--stats", action="store_true")
parser.add_argument("-r", "--dump-mid-ir", action="store_true")
parser.add_argument("--arm", action="store_true")
parser.add_argument("-n", "--no-execute", action="store_true")
parser.add_argument("-d", "--directory", type=str)
parser.add_argument("--timeout", type=float, default=0.5)
parser.add_argument("--asm", type=str)
parser.add_argument("-t", "--test", type=str)

args = parser.parse_args()

SRC_DIR = Path("src")
BUILD_DIR = Path("build")
FINAL_BINARY = BUILD_DIR / "sysc"
COMPILER = "clang++"
AR = "ar"
CFLAGS = ["-c", "-std=c++17", "-g"]
LDFLAGS = []
CACHE_FILE = BUILD_DIR / ".build_cache.pkl"

def hash_file(path):
  h = hashlib.sha256()
  with open(path, 'rb') as f:
    h.update(f.read())
  return h.hexdigest()

def find_files():
  cpp_files = []
  h_files = []
  for path in SRC_DIR.rglob("*"):
    if path.suffix == ".cpp":
      cpp_files.append(path)
    elif path.suffix == ".h":
      h_files.append(path)
  return cpp_files, h_files

def load_cache():
  if CACHE_FILE.exists():
    with open(CACHE_FILE, "rb") as f:
      return pickle.load(f)
  return {}

def save_cache(cache):
  BUILD_DIR.mkdir(parents=True, exist_ok=True)
  with open(CACHE_FILE, "wb") as f:
    pickle.dump(cache, f)

def needs_recompile(src_path, obj_path, cache, dependencies):
  src_hash = hash_file(src_path)
  dep_hashes = { str(dep): hash_file(dep) for dep in dependencies }

  prev = cache.get(str(src_path))
  if not prev:
      return True
  if prev['src_hash'] != src_hash:
      return True
  if prev['dep_hashes'] != dep_hashes:
      return True
  if not obj_path.exists():
      return True
  return False

def get_includes(src_path):
  includes = []
  with open(src_path, "r") as f:
    for line in f:
      line = line.strip()
      if line.startswith("#include \""):
        header = line.split("\"")[1]
        include_path = src_path.parent / header
        if include_path.exists():
          includes.append(include_path.resolve())
  return includes

def compile_cpp(src_path, obj_path):
  obj_path.parent.mkdir(parents=True, exist_ok=True)
  print(f"Compiling {src_path} -> {obj_path}")
  proc.check_call([COMPILER] + CFLAGS + ["-o", str(obj_path), str(src_path)])

def archive_objects(obj_files, lib_path):
  if lib_path.exists():
      lib_path.unlink()
  print(f"Creating archive {lib_path}")
  proc.check_call([AR, "rcs", str(lib_path)] + [str(obj) for obj in obj_files])

def link_libraries(lib_files, output_binary):
  print(f"Linking {output_binary}")
  proc.check_call([COMPILER] + LDFLAGS + ["-o", str(output_binary)] + [str(lib) for lib in lib_files])

def build():
  cpp_files, _ = find_files()
  cache = load_cache()

  # Step 1: Compile .cpp to .o
  obj_files = []
  folder_changed = {}
  for cpp in cpp_files:
    rel_dir = cpp.relative_to(SRC_DIR).parent
    obj_dir = BUILD_DIR / rel_dir
    obj_path = obj_dir / (cpp.stem + ".o")

    dependencies = get_includes(cpp)
    if needs_recompile(cpp, obj_path, cache, dependencies):
      compile_cpp(cpp, obj_path)
      cache[str(cpp)] = {
        'src_hash': hash_file(cpp),
        'dep_hashes': {str(dep): hash_file(dep) for dep in dependencies},
      }
      folder_changed[rel_dir] = True
    obj_files.append((rel_dir, obj_path))

  # Step 2: Archive .o's in same folder into .a
  folder_objs = {}
  for rel_dir, obj in obj_files:
    folder_objs.setdefault(rel_dir, []).append(obj)

  lib_files = []
  for folder, objs in folder_objs.items():
    lib_path = BUILD_DIR / folder / (folder.name + ".a")
    need_archive = folder_changed.get(folder, False) or not lib_path.exists()
    if need_archive:
      archive_objects(objs, lib_path)
    else:
      print(f"Skipping archive {lib_path}, no changes")
    lib_files.append(lib_path)

  # Step 3: Link all .a's into final binary
  link_libraries(lib_files, FINAL_BINARY)

  save_cache(cache)


def run_asm(file: str):
  basename = os.path.splitext(os.path.basename(file))[0]

  # Invoke gcc.
  gcc = "aarch64-linux-gnu-gcc" if args.arm else "riscv64-linux-gnu-gcc"
  proc.run([gcc, file, "test/official/sylib.c", "-static", "-o", f"temp/{basename}"], check=True)

  # Run the file.
  qemu = "qemu-aarch64-static" if args.arm else "qemu-riscv64-static"
  return proc.run([qemu, f"temp/{basename}"])

def run(full_file: str, no_exec: bool):
  basename = os.path.splitext(os.path.basename(full_file))[0]

  command = [f"{BUILD_DIR}/sysc", f"test/{full_file}"]

  if args.gdb:
    command = ["gdb", "--args", *command]
    no_exec = True
  
  if args.valgrind:
    command = ["valgrind", *command]
    no_exec = True
  
  if args.dump_mid_ir:
    command.append("--dump-mid-ir")
  
  if args.arm:
    command.append("--arm")
  
  if args.verbose:
    command.append("-v")
  
  if args.stats:
    command.append("--stats")

  command.extend(["-o", f"temp/{basename}.s"])
  
  # Invoke SysY compiler.
  proc.run(command, check=True)

  if no_exec:
    return;
  return run_asm(f"temp/{basename}.s")

def test_all():
  passed = 0
  total = 0
  failures = []
  
  # Collect all test cases
  test_cases = []
  directory = args.directory
  for root, _, files in os.walk(directory):
    for file in files:
      if file.endswith('.sy'):
        sy_path: Path = Path(root) / file
        base = sy_path.stem
        in_path = sy_path.with_name(f"{base}.in")
        out_path = sy_path.with_name(f"{base}.out")
        
        if not out_path.exists():
          print(f"Warning: {sy_path} missing .out file, skipping")
          continue;
          
        test_cases.append((sy_path, in_path if in_path.exists() else None, out_path))
  
  total = len(test_cases)
  
  for sy_path, in_path, out_path in test_cases:
    test_name = f"{sy_path.parent.name}/{sy_path.name}"
    print(f"Testing {test_name}...", end='\r')
    
    with tempfile.TemporaryDirectory() as tmpdir:
      asm_path = Path(tmpdir) / "output.s"
      exe_path = Path(tmpdir) / "a.out"
      
      # Step 1: Compile .sy to .s using sysc
      try:
        proc.run(
          [f"{BUILD_DIR}/sysc", str(sy_path), "-o", str(asm_path)],
          check=True,
          stdout=proc.PIPE,
          stderr=proc.STDOUT,
          timeout=args.timeout
        )
      except proc.CalledProcessError as e:
        failures.append((sy_path, f"Compile failed: {e.output.decode().strip()}"))
        continue
      except proc.TimeoutExpired:
        failures.append((sy_path, f"Compiler timeout ({args.timeout:.2f}s)"))
        continue
        
      if not asm_path.exists():
        failures.append((sy_path, "No assembly output generated"))
        continue
      
      try:
        gcc = "aarch64-linux-gnu-gcc" if args.arm else "riscv64-linux-gnu-gcc"
        proc.run(
          [gcc, "-static", str(asm_path), "test/official/sylib.c", "-o", str(exe_path)],
          check=True,
          stdout=proc.PIPE,
          stderr=proc.STDOUT
        )
      except proc.CalledProcessError as e:
        failures.append((sy_path, f"Linking failed: {e.output.decode().strip()}"))
        continue
        
      if not exe_path.exists():
        failures.append((sy_path, "No executable generated after linking"))
        continue
        
      # Step 3: Run with QEMU
      input_data = None
      if in_path:
        with open(in_path, 'r') as f:
          input_data = f.read()
      
      try:
        qemu = "qemu-aarch64-static" if args.arm else "qemu-riscv64-static"
        result = proc.run(
          f"{qemu} {str(exe_path)}",
          input=input_data,
          stdout=proc.PIPE,
          stderr=proc.DEVNULL,
          timeout=args.timeout,
          shell=True
        )
        actual_out: str = result.stdout.decode('utf-8')
        actual = f"{actual_out}\n{result.returncode}".strip()
      except proc.TimeoutExpired:
        failures.append((sy_path, f"Timeout ({args.timeout:.2f}s)"))
        continue
      except Exception as e:
        failures.append((sy_path, f"Runtime error: {str(e)}"))
        continue

      with open(out_path) as f:
        expected = f.read().strip()
        
      if actual != expected:
        failures.append((sy_path, f"Output mismatch: {actual}"))
      else:
        passed += 1
  
  # Print results
  print("\nTest results:")
  print(f"Total:  {total}")
  print(f"Passed: {passed}")
  print(f"Failed: {len(failures)}")
  
  if failures:
    print("\nFailed cases:")
    failures = sorted(failures, key=lambda x: x[0])
    for path, reason in failures:
      print(f"- {path}")
      first_line = reason.split('\n')[0].strip()
      print(f"  Reason: {first_line}")


if __name__ == "__main__":
  if args.asm:
    result = run_asm(args.asm)
    print("Return value: ", result.returncode)
    exit(0)

  build()

  if args.directory:
    test_all()

  if args.test:
    result = run(args.test, args.no_execute)
    if result is not None:
      print("Return value:", result.returncode)
